{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup environment and dependencies**\n",
    "\n",
    "Note: This notebook is experted from kaggle personal account\n",
    "\n",
    "    - pip install uv\n",
    "    - pyenv to manage python version\n",
    "    - using 3.11\n",
    "    - uv sync\n",
    "    - unzip data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv add numpy pandas \n",
    "!uv add nltk gensim\n",
    "!uv add scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using gensim -> True\n",
    "# to use nltk stemming set False\n",
    "USE_GENSIM=True\n",
    "# USE_GENSIM=False\n",
    "\n",
    "# gensim takes 0.6 s for me and nltk took 2.5 test twice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-12T12:30:23.311058Z",
     "iopub.status.busy": "2025-10-12T12:30:23.310494Z",
     "iopub.status.idle": "2025-10-12T12:30:25.415088Z",
     "shell.execute_reply": "2025-10-12T12:30:25.413007Z",
     "shell.execute_reply.started": "2025-10-12T12:30:23.311026Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "**Short description**\n",
    "- Load datasets into DF using pd\n",
    "    - Explore datasets\n",
    "    - shape\n",
    "    - columns info()\n",
    "    - datatypes\n",
    "    - head and head(count)\n",
    "- combine dataframes into one using merge\n",
    "    - droped title from credits and used only movie_id, inplace=True\n",
    "    - merge(on=Column name)\n",
    "    - merge left_on, right_on used becuase i used id and movie_id and with innner as how\n",
    "- feature selection\n",
    "  - Null checks\n",
    "  - duplicate checks\n",
    "  - drop null\n",
    "- data preprocessing\n",
    "- Vectorization\n",
    "- Main function to return movies\n",
    "- Saving Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "- Load datasets into DF using pd\n",
    "    - Explore datasets\n",
    "    - shape\n",
    "    - columns info()\n",
    "    - datatypes\n",
    "    - head and head(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T12:31:04.390648Z",
     "iopub.status.busy": "2025-10-12T12:31:04.390264Z",
     "iopub.status.idle": "2025-10-12T12:31:05.401723Z",
     "shell.execute_reply": "2025-10-12T12:31:05.400316Z",
     "shell.execute_reply.started": "2025-10-12T12:31:04.390624Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv('data/tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv('data/tmdb_5000_credits.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T12:31:41.829722Z",
     "iopub.status.busy": "2025-10-12T12:31:41.829366Z",
     "iopub.status.idle": "2025-10-12T12:31:41.836156Z",
     "shell.execute_reply": "2025-10-12T12:31:41.835133Z",
     "shell.execute_reply.started": "2025-10-12T12:31:41.829697Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Movies DF shape:\", movies.shape, \"Credits DF shape:\", credits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-10-12T12:31:54.379098Z",
     "iopub.status.busy": "2025-10-12T12:31:54.378785Z",
     "iopub.status.idle": "2025-10-12T12:31:54.418826Z",
     "shell.execute_reply": "2025-10-12T12:31:54.417632Z",
     "shell.execute_reply.started": "2025-10-12T12:31:54.379074Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-10-12T12:32:06.126198Z",
     "iopub.status.busy": "2025-10-12T12:32:06.125909Z",
     "iopub.status.idle": "2025-10-12T12:32:06.143177Z",
     "shell.execute_reply": "2025-10-12T12:32:06.141684Z",
     "shell.execute_reply.started": "2025-10-12T12:32:06.126178Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credits.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-10-12T12:36:16.813487Z",
     "iopub.status.busy": "2025-10-12T12:36:16.813150Z",
     "iopub.status.idle": "2025-10-12T12:36:16.851869Z",
     "shell.execute_reply": "2025-10-12T12:36:16.850477Z",
     "shell.execute_reply.started": "2025-10-12T12:36:16.813465Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-10-12T12:41:06.613018Z",
     "iopub.status.busy": "2025-10-12T12:41:06.612713Z",
     "iopub.status.idle": "2025-10-12T12:41:06.624640Z",
     "shell.execute_reply": "2025-10-12T12:41:06.623438Z",
     "shell.execute_reply.started": "2025-10-12T12:41:06.612996Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credits.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "- combine dataframes into one using merge\n",
    "    - droped title from credits and used only movie_id, inplace=True\n",
    "    - merge(on=Column name)\n",
    "    - merge left_on, right_on used becuase i used id and movie_id and with innner as how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-10-12T12:44:45.382870Z",
     "iopub.status.busy": "2025-10-12T12:44:45.382533Z",
     "iopub.status.idle": "2025-10-12T12:44:45.450055Z",
     "shell.execute_reply": "2025-10-12T12:44:45.448645Z",
     "shell.execute_reply.started": "2025-10-12T12:44:45.382850Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "movies.merge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T12:50:24.500782Z",
     "iopub.status.busy": "2025-10-12T12:50:24.500470Z",
     "iopub.status.idle": "2025-10-12T12:50:24.509477Z",
     "shell.execute_reply": "2025-10-12T12:50:24.507806Z",
     "shell.execute_reply.started": "2025-10-12T12:50:24.500762Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credits.drop('title', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T12:51:55.024107Z",
     "iopub.status.busy": "2025-10-12T12:51:55.023801Z",
     "iopub.status.idle": "2025-10-12T12:51:55.034244Z",
     "shell.execute_reply": "2025-10-12T12:51:55.033099Z",
     "shell.execute_reply.started": "2025-10-12T12:51:55.024086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "movies = movies.merge(credits, left_on=['id'], right_on=['movie_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T12:51:57.715725Z",
     "iopub.status.busy": "2025-10-12T12:51:57.714869Z",
     "iopub.status.idle": "2025-10-12T12:51:57.735922Z",
     "shell.execute_reply": "2025-10-12T12:51:57.734911Z",
     "shell.execute_reply.started": "2025-10-12T12:51:57.715696Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "movies.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 3\n",
    "- feature selection\n",
    "  - Null checks\n",
    "  - duplicate checks\n",
    "  - drop null\n",
    "\n",
    "**Selected Feature**\n",
    "* genre\n",
    "* keywords\n",
    "* title -> english\n",
    "* overview\n",
    "* cast -> name -> Actors real name -> top 3\n",
    "* crew -> Director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "_movies = movies[['id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]\n",
    "_movies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_movies.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = _movies.dropna()\n",
    "movies.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 4\n",
    "\n",
    "- data preprocessing\n",
    "  - Cleanup for columns like genres, keywords, cast, crew\n",
    "  - Spaces cleanup\n",
    "  - Tags combined column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'][0]\n",
    "\n",
    "# reading 0 index will return string\n",
    "movies['genres'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp testing\n",
    "import json\n",
    "temp= json.loads(movies['genres'][0])\n",
    "\n",
    "print(\"data at 0\", temp[0], \"\\nname at 0\", temp[0]['name'])\n",
    "\n",
    "# or use ast.literal_eval\n",
    "# import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_parser(data_obj, data_key='name'):\n",
    "    d_list = []\n",
    "    try:\n",
    "        data = json.loads(data_obj)\n",
    "        for item in data:\n",
    "            d_list.append(item[data_key])   \n",
    "    except Exception:\n",
    "        print(\"Error\")\n",
    "        d_list.append(None)\n",
    "    return d_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genres'].apply(lambda x: data_parser(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['keywords'] = movies['keywords'].apply(lambda x: data_parser(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_parser(data_obj, data_key='name', limit=3):\n",
    "    d_list = []\n",
    "    try:\n",
    "        data = json.loads(data_obj)\n",
    "        data = data[:limit]\n",
    "        for item in data:\n",
    "            d_list.append(item[data_key])   \n",
    "    except Exception:\n",
    "        print(\"Error\")\n",
    "        d_list.append(None)\n",
    "    return d_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['cast'] = movies['cast'].apply(lambda x: cast_parser(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['crew'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def director_crew_parser(data_obj, data_key='name'):\n",
    "    d_list = []\n",
    "    try:\n",
    "        data = json.loads(data_obj)\n",
    "        for item in data:\n",
    "            if item['job'] == 'Director':\n",
    "                d_list.append(item[data_key])   \n",
    "                break\n",
    "    except Exception:\n",
    "        print(\"Error\")\n",
    "        d_list.append(None)\n",
    "    return d_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['crew'] = movies['crew'].apply(lambda x: director_crew_parser(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['overview'] = movies['overview'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.loc[:,'genres'] = movies['genres'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n",
    "movies.loc[:,'keywords'] = movies['keywords'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n",
    "movies.loc[:,'cast'] = movies['cast'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n",
    "movies.loc[:,'crew'] = movies['crew'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.loc[:, 'tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = movies[['id', 'title', 'tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['tags'] = main_df['tags'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['tags'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can leverage CountVectoriser to apply lowercase\n",
    "main_df['tags'] = main_df['tags'].apply(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5\n",
    "\n",
    "Vectorization\n",
    "\n",
    "* Text vectorization\n",
    "    * Text similarity between tags\n",
    "    * Stop words removal\n",
    "    * 5000 minimal words for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=5000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = cv.fit_transform(main_df['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.get_feature_names_out()[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_GENSIM:\n",
    "    from gensim.parsing.porter import PorterStemmer\n",
    "    ps = PorterStemmer()\n",
    "    print(\"gensim\")\n",
    "else:\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    ps = PorterStemmer()\n",
    "    print(\"nltk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(input:str)->str:\n",
    "    out = [ps.stem(i) for i in input.split()]\n",
    "    return \" \".join(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem(main_df['tags'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim\n",
    "# 'in the 22nd century, a parapleg marin is dispatch to the moon pandora on a uniqu mission, \n",
    "# but becom torn between follow order and protect an alien civilization. action adventur fantasi\n",
    "# sciencefict cultureclash futur spacewar spacecoloni societi spacetravel futurist romanc space alien tribe alienplanet cgi \n",
    "# marin soldier battl loveaffair antiwar powerrel mindandsoul 3d samworthington zoesaldana sigourneyweav jamescameron'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk\n",
    "# 'in the 22nd century, a parapleg marin is dispatch to the moon pandora on a uniqu mission,\n",
    "# but becom torn between follow order and protect an alien civilization. action adventur fantasi\n",
    "# sciencefict cultureclash futur spacewar spacecoloni societi spacetravel futurist romanc space alien tribe alienplanet cgi\n",
    "# marin soldier battl loveaffair antiwar powerrel mindandsoul 3d samworthington zoesaldana sigourneyweav jamescameron'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.loc[:, 'tags'] = main_df['tags'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = cv.fit_transform(main_df['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.get_feature_names_out()[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6\n",
    "\n",
    "Similarity between movies to other movies\n",
    "some chart like heatmap\n",
    "* Create similarity matrix\n",
    "* cosine similarity -> uses angles\n",
    "* using indexes to get similarity matrix\n",
    "* return movie data using index and main df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(main_df[main_df['title']=='Avatar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movie(movie_name):\n",
    "    # get movie data from df matching to title\n",
    "    # movie = main_df[main_df['title'] == movie_name]\n",
    "\n",
    "    # using lowercase for better comparision\n",
    "    movie = main_df[main_df[\"title\"].str.lower() == movie_name.lower()]\n",
    "\n",
    "    if movie.empty:\n",
    "        out = {\"status\": \"success\", \"data\": []}\n",
    "        return out\n",
    "\n",
    "    # get index to so similarity matrix can be used to get similarity based of index\n",
    "    movie_index = movie.index[0]\n",
    "\n",
    "    # get similarity matrix of this movie using movie_index\n",
    "    movie_similarity_matrix = similarity[movie_index]\n",
    "\n",
    "    # need to sort to get top highest similarity based movies and keeping the indexes at same place or maybe\n",
    "    # known\n",
    "    closest_movies_sorted = sorted(\n",
    "        enumerate(movie_similarity_matrix), reverse=True, key=lambda x: x[1]\n",
    "    )\n",
    "    similar_movies_five: list[tuple[int, np.float64]] = closest_movies_sorted[1:6]\n",
    "    # [(1213, np.float64(0.2847987184339659))] -> [(index, similarity)]\n",
    "\n",
    "    recommended_movies = [\n",
    "        {\n",
    "            \"movie_id\": main_df.loc[item[0]].id,\n",
    "            \"movie_name\": main_df.loc[item[0]].title,\n",
    "            \"movie_index\": item[0],\n",
    "            \"movie_similarity\": item[1],\n",
    "        }\n",
    "        for item in similar_movies_five\n",
    "    ]\n",
    "\n",
    "    out = {\"status\": \"success\", \"data\": recommended_movies}\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_movie('Moon knight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movie_by_id(movie_id):\n",
    "    # get movie data from df matching to id\n",
    "\n",
    "    # using lowercase for better comparision\n",
    "    movie = main_df[main_df[\"id\"] == movie_id]\n",
    "\n",
    "    if movie.empty:\n",
    "        out = {\"status\": \"success\", \"data\": []}\n",
    "        return out\n",
    "\n",
    "    # get index to so similarity matrix can be used to get similarity based of index\n",
    "    movie_index = movie.index[0]\n",
    "\n",
    "    # get similarity matrix of this movie using movie_index\n",
    "    movie_similarity_matrix = similarity[movie_index]\n",
    "\n",
    "    # need to sort to get top highest similarity based movies and keeping the indexes at same place or maybe\n",
    "    # known\n",
    "    closest_movies_sorted = sorted(\n",
    "        enumerate(movie_similarity_matrix), reverse=True, key=lambda x: x[1]\n",
    "    )\n",
    "    similar_movies_five: list[tuple[int, np.float64]] = closest_movies_sorted[1:6]\n",
    "    # [(1213, np.float64(0.2847987184339659))] -> [(index, similarity)]\n",
    "\n",
    "    recommended_movies = [\n",
    "        {\n",
    "            \"movie_id\": main_df.loc[item[0]].id,\n",
    "            \"movie_name\": main_df.loc[item[0]].title,\n",
    "            \"movie_index\": item[0],\n",
    "            \"movie_similarity\": item[1],\n",
    "        }\n",
    "        for item in similar_movies_five\n",
    "    ]\n",
    "\n",
    "    out = {\"status\": \"success\", \"data\": recommended_movies}\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_movie_by_id(19995)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7\n",
    "\n",
    "- backup for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "movies_df = main_df[['id', 'title']]\n",
    "movies_df.sort_values(by='title', ascending=True, inplace=True)\n",
    "joblib.dump((movies_df, similarity), 'movies_recommendations_assets_min.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, similarity_matrix = joblib.load(\"movie_recommendation_assets.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df[['id', 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recommend_movies():\n",
    "#     movie_id = '19995'\n",
    "#     main_df, similarity = joblib.load(\"movie_recommendation_assets.joblib\")\n",
    "\n",
    "#     # get movie data from df matching to id\n",
    "#     movie = main_df[main_df[\"id\"] == int(movie_id) ]\n",
    "\n",
    "#     if movie.empty:\n",
    "#         out = {\"status\": \"success\", \"data\": []}\n",
    "#         return out\n",
    "\n",
    "#     # get index to so similarity matrix can be used to get similarity based of index\n",
    "#     movie_index = movie.index[0]\n",
    "\n",
    "#     # get similarity matrix of this movie using movie_index\n",
    "#     movie_similarity_matrix = similarity[movie_index]\n",
    "\n",
    "#     # need to sort to get top highest similarity based movies and keeping the indexes at same place or maybe\n",
    "#     # known\n",
    "#     closest_movies_sorted = sorted(\n",
    "#         enumerate(movie_similarity_matrix), reverse=True, key=lambda x: x[1]\n",
    "#     )\n",
    "#     similar_movies_five: list[tuple[int, np.float64]] = closest_movies_sorted[1:6]\n",
    "#     # [(1213, np.float64(0.2847987184339659))] -> [(index, similarity)]\n",
    "\n",
    "#     recommended_movies = [\n",
    "#         {\n",
    "#             \"movie_id\": main_df.loc[item[0]].id,\n",
    "#             \"movie_name\": main_df.loc[item[0]].title,\n",
    "#             \"movie_index\": item[0],\n",
    "#             \"movie_similarity\": item[1],\n",
    "#         }\n",
    "#         for item in similar_movies_five\n",
    "#     ]\n",
    "\n",
    "#     out = {\"status\": \"success\", \"data\": recommended_movies}\n",
    "\n",
    "#     return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 138,
     "sourceId": 4508,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "movie-recommendation-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
